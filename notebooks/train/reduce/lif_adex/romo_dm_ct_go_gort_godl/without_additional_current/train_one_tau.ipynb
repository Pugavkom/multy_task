{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание\n",
    "\n",
    "## Задачи\n",
    "_Испольуется три задачи:_\n",
    "- DM -- двухальтернативный выбор\n",
    "- Romo -- сравнение двух сигнало через задержку\n",
    "- CtxDM -- DM с контекстом\n",
    "Вход состоит из одного контекстного входа, одного стимула, 6 входов, кодирующих задачи. Выход как и раньше состоит из трех частей: контекстный выход, выходы принятия решения.\n",
    "\n",
    "## Сеть\n",
    " Сеть состоит из lif AdEx нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт всех необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from cgtasknet.instruments.instrument_accuracy_network import CorrectAnswerNetwork\n",
    "from cgtasknet.tasks.reduce import (\n",
    "    CtxDMTaskParameters,\n",
    "    DMTaskParameters,\n",
    "    DMTaskRandomModParameters,\n",
    "    GoDlTaskParameters,\n",
    "    GoDlTaskRandomModParameters,\n",
    "    GoRtTaskParameters,\n",
    "    GoRtTaskRandomModParameters,\n",
    "    GoTaskParameters,\n",
    "    GoTaskRandomModParameters,\n",
    "    MultyReduceTasks,\n",
    "    RomoTaskParameters,\n",
    "    RomoTaskRandomModParameters,\n",
    ")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определяем устройство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функция построения входов и выходов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def plot_results(inputs, target_outputs, outputs):\n",
    "    if isinstance(inputs, torch.Tensor) and isinstance(target_outputs, torch.Tensor):\n",
    "        inputs, t_outputs = (\n",
    "            inputs.detach().cpu().numpy(),\n",
    "            target_outputs.detach().cpu().numpy(),\n",
    "        )\n",
    "    for bath in range(min(batch_size, 20)):\n",
    "        fig = plt.figure(figsize=(15, 3))\n",
    "        ax1 = fig.add_subplot(141)\n",
    "        plt.title(\"Inputs\")\n",
    "        plt.xlabel(\"$time, ms$\")\n",
    "        plt.ylabel(\"$Magnitude$\")\n",
    "        for i in range(3):\n",
    "            plt.plot(inputs[:, bath, i].T, label=rf\"$in_{i + 1}$\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        ax2 = fig.add_subplot(142)\n",
    "        plt.title(\"Task code (context)\")\n",
    "        plt.xticks(np.arange(1, len(tasks) + 1), sorted(tasks), rotation=90)\n",
    "        plt.yticks([])\n",
    "        for i in range(3, inputs.shape[-1]):\n",
    "            plt.plot([i - 2] * 2, [0, inputs[0, bath, i]])\n",
    "        plt.tight_layout()\n",
    "\n",
    "        ax3 = fig.add_subplot(143)\n",
    "        plt.title(\"Target output\")\n",
    "        plt.xlabel(\"$time, ms$\")\n",
    "        for i in range(t_outputs.shape[-1]):\n",
    "            plt.plot(t_outputs[:, bath, i], label=rf\"$out_{i + 1}$\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        ax4 = fig.add_subplot(144)\n",
    "        plt.title(\"Real output\")\n",
    "        plt.xlabel(\"$time, ms$\")\n",
    "        for i in range(outputs.shape[-1]):\n",
    "            plt.plot(\n",
    "                outputs.detach().cpu().numpy()[:, bath, i], label=rf\"$out_{i + 1}$\"\n",
    "            )\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        if not os.path.exists(\"figures\"):\n",
    "            os.mkdir(\"figures\")\n",
    "        plt.savefig(f\"figures{os.sep}network_outputs_{name}_batch_{bath}.pdf\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Определяем датасет\n",
    "Датасет будет состоять из трех типов задач:\n",
    "- DM задача;\n",
    "- Romo задача;\n",
    "- CtxDM задача.\n",
    "_Параметры для последней задачи аналогичны DM задаче_\n",
    "***\n",
    "## Параметры датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "number_of_epochs = 3000\n",
    "number_of_tasks = 1\n",
    "\n",
    "go_task_list_values = np.linspace(0, 1, 8)\n",
    "\n",
    "romo_parameters = RomoTaskRandomModParameters(\n",
    "    romo=RomoTaskParameters(\n",
    "        delay=0.2,\n",
    "        positive_shift_delay_time=1.5,\n",
    "        trial_time=0.2,\n",
    "        positive_shift_trial_time=0.4,\n",
    "        answer_time=0.25,\n",
    "    ),\n",
    ")\n",
    "dm_parameters = DMTaskRandomModParameters(\n",
    "    dm=DMTaskParameters(trial_time=0.3, positive_shift_trial_time=1.5, answer_time=0.25)\n",
    ")\n",
    "ctx_parameters = CtxDMTaskParameters(dm=dm_parameters.dm)\n",
    "go_parameters = GoTaskRandomModParameters(\n",
    "    go=GoTaskParameters(\n",
    "        trial_time=0.3,\n",
    "        positive_shift_trial_time=1.5,\n",
    "        value=go_task_list_values,\n",
    "        answer_time=0.25,\n",
    "    )\n",
    ")\n",
    "gort_parameters = GoRtTaskRandomModParameters(\n",
    "    go_rt=GoRtTaskParameters(\n",
    "        trial_time=0.3,\n",
    "        positive_shift_trial_time=1.5,\n",
    "        answer_time=1.5,\n",
    "        value=go_task_list_values,\n",
    "    )\n",
    ")\n",
    "godl_parameters = GoDlTaskRandomModParameters(\n",
    "    go_dl=GoDlTaskParameters(\n",
    "        go=GoTaskParameters(\n",
    "            trial_time=0.2,\n",
    "            positive_shift_trial_time=0.4,\n",
    "            answer_time=0.25,\n",
    "            value=go_task_list_values,\n",
    "        ),\n",
    "        delay=0.2,\n",
    "        positive_shift_delay_time=1.5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 0.5\n",
    "tasks = [\n",
    "    \"RomoTask1\",\n",
    "    \"RomoTask2\",\n",
    "    \"DMTask1\",\n",
    "    \"DMTask2\",\n",
    "    \"CtxDMTask1\",\n",
    "    \"CtxDMTask2\",\n",
    "    \"GoTask1\",\n",
    "    \"GoTask2\",\n",
    "    \"GoRtTask1\",\n",
    "    \"GoRtTask2\",\n",
    "    \"GoDlTask1\",\n",
    "    \"GoDlTask2\",\n",
    "]\n",
    "task_dict = {\n",
    "    tasks[0]: romo_parameters,\n",
    "    tasks[1]: romo_parameters,\n",
    "    tasks[2]: dm_parameters,\n",
    "    tasks[3]: dm_parameters,\n",
    "    tasks[4]: ctx_parameters,\n",
    "    tasks[5]: ctx_parameters,\n",
    "    tasks[6]: go_parameters,\n",
    "    tasks[7]: go_parameters,\n",
    "    tasks[8]: gort_parameters,\n",
    "    tasks[9]: gort_parameters,\n",
    "    tasks[10]: godl_parameters,\n",
    "    tasks[11]: godl_parameters,\n",
    "}\n",
    "Task = MultyReduceTasks(\n",
    "    tasks=task_dict,\n",
    "    batch_size=batch_size,\n",
    "    delay_between=0,\n",
    "    enable_fixation_delay=True,\n",
    "    mode=\"random\",\n",
    ")\n",
    "\n",
    "print(\"Task parameters:\")\n",
    "for key in task_dict:\n",
    "    print(f\"{key}:\\n{task_dict[key]}\\n\")\n",
    "\n",
    "print(f\"inputs/outputs: {Task.feature_and_act_size[0]}/{Task.feature_and_act_size[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorted_tasks = sorted(tasks)\n",
    "re_word = \"Go\"\n",
    "choices_tasks = []\n",
    "values_tasks = []\n",
    "for i in range(len(sorted_tasks)):\n",
    "    if re_word in sorted_tasks[i]:\n",
    "        values_tasks.append(i)\n",
    "    else:\n",
    "        choices_tasks.append(i)\n",
    "can = CorrectAnswerNetwork(choices_tasks, values_tasks, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализация сети и выгрузка на device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cgtasknet.net import SNNlifadex\n",
    "from norse.torch import LIFAdExParameters\n",
    "\n",
    "feature_size, output_size = Task.feature_and_act_size\n",
    "hidden_size = 400\n",
    "\n",
    "neuron_parameters = LIFAdExParameters(\n",
    "    v_th=torch.as_tensor(0.65),\n",
    "    tau_ada_inv=torch.as_tensor(1 / 2.0),\n",
    "    alpha=100,\n",
    "    method=\"super\",\n",
    "    # rho_reset = torch.as_tensor(5)\n",
    ")\n",
    "model = SNNlifadex(\n",
    "    feature_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    neuron_parameters=neuron_parameters,\n",
    "    tau_filter_inv=50,\n",
    "    save_states=True,\n",
    "    return_spiking=True,\n",
    ").to(device)\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"alif.recurrent_weights\":\n",
    "        initial_parameters = torch.clone(param.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "inputs, _ = Task.dataset(1)\n",
    "inputs *= 0\n",
    "additionalCurrent = 0.1 * torch.randn((1, hidden_size)).to(device) + 1.4\n",
    "inputs = torch.from_numpy(inputs[-1000:]).type(torch.float).to(device)\n",
    "outputs, states = model(inputs, additional_current = additionalCurrent)\n",
    "outputs = outputs.detach().cpu()\n",
    "plt.plot(outputs[:, 0, 0])\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "mean_fr = torch.zeros((hidden_size))\n",
    "\n",
    "for i in range(len(states)):\n",
    "    mean_fr += torch.mean(states[i].z.detach().cpu(), axis=0)\n",
    "mean_fr /= len(states)\n",
    "plt.plot(mean_fr == 0, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "mean_fr = torch.zeros((hidden_size))\n",
    "\n",
    "for i in range(len(states)):\n",
    "    mean_fr += torch.mean(states[i].z.detach().cpu(), axis=0)\n",
    "mean_fr /= len(states)\n",
    "plt.plot(mean_fr, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Критерий и функция ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-3\n",
    "reg_freq = 1e5\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        return torch.sqrt(self.mse(yhat, y))\n",
    "\n",
    "\n",
    "class MaskedMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, mask):\n",
    "        diff2 = (torch.flatten(input) - torch.flatten(target)) ** 2.0 * torch.flatten(\n",
    "            mask\n",
    "        )\n",
    "        result = torch.sum(diff2) / torch.sum(mask)\n",
    "        return result\n",
    "\n",
    "\n",
    "class MaskedAndFrRegMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedAndFrRegMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, mask, state):\n",
    "        diff2 = (torch.flatten(input) - torch.flatten(target)) ** 2.0 * torch.flatten(\n",
    "            mask\n",
    "        )\n",
    "        result = torch.sum(diff2) / torch.sum(mask)\n",
    "        s = []\n",
    "        for i in range(len(state)):\n",
    "            s.append(state[i])\n",
    "        s = torch.stack(s)\n",
    "        fr_neurons_mean = torch.mean(torch.mean(s, axis=0), axis=0)\n",
    "        coefs = ((fr_neurons_mean > 0.01)).detach()\n",
    "        fr_neurons_mean *= coefs\n",
    "        fr_neurons_mean = torch.mean(fr_neurons_mean)\n",
    "        result += fr_neurons_mean**2 * reg_freq\n",
    "        return result\n",
    "\n",
    "\n",
    "criterion = MaskedAndFrRegMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация всех эпох\n",
    "> Если память не позволяет, то необходимо генерировать каждую эпоху в основном цикле обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    list_inputs = []\n",
    "    list_t_outputs = []\n",
    "    for i in tqdm(range(number_of_epochs)):\n",
    "        temp_input, temp_t_output = Task.dataset()\n",
    "        temp_input.astype(dtype=np.float16)\n",
    "        temp_t_output.astype(dtype=np.float16)\n",
    "        temp_input[:, :, :] += np.random.normal(0, sigma, size=temp_input.shape)\n",
    "        list_inputs.append(temp_input)\n",
    "        list_t_outputs.append(temp_t_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JIT numba generator (test)\n",
    "TODO: Необходимо добавить в cgtasknet и вызывать оттуда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "\n",
    "@njit(cache=True, parallel=True)\n",
    "def every_bath_generator(\n",
    "    start_sigma: float,\n",
    "    stop_sigma: float,\n",
    "    times: int = 1,\n",
    "    batches: int = 1,\n",
    "    actions: int = 1,\n",
    "):\n",
    "    data = np.zeros((times, batches, actions))\n",
    "    for i in prange(batches):\n",
    "        data[:, i, :] = np.random.normal(\n",
    "            0, np.random.uniform(start_sigma, stop_sigma), size=(times, actions)\n",
    "        )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def additional_current_generate(\n",
    "    nt: int, batch_size: int, hidden_size: int, base_current_in: torch.tensor = None\n",
    "):\n",
    "    base_current = torch.zeros((nt, batch_size, hidden_size))\n",
    "    if base_current_in is None:\n",
    "        base_current[0, ...] = torch.empty((batch_size, hidden_size)).normal_(\n",
    "            mean=0.0, std=0.1\n",
    "        )\n",
    "    else:\n",
    "        base_current[0, ...] = base_current_in\n",
    "    noise = torch.empty_like(base_current).normal_(\n",
    "        mean=0.0, std=torch.sqrt(torch.tensor(0.001))\n",
    "    )\n",
    "    for i in range(nt - 1):\n",
    "        base_current[i + 1, ...] = base_current[i, ...] + noise[i, ...]\n",
    "    return base_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основной цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cgtasknet.instruments.instrument_accuracy_network import correct_answer\n",
    "from cgtasknet.net.states import LIFAdExInitState\n",
    "from norse.torch import LIFAdExState\n",
    "\n",
    "name = f\"Train_dm_and_romo_task_reduce_lif_adex_without_refrac_random_delay_long_a_alpha_{neuron_parameters.alpha}_N_{hidden_size}\"\n",
    "init_state = LIFAdExInitState(batch_size, hidden_size, device=device)\n",
    "running_loss = 0\n",
    "sigma = 0\n",
    "\n",
    "for i in tqdm(range(number_of_epochs)):\n",
    "    if i == 500:\n",
    "        sigma = 0.2\n",
    "    if i == 1000:\n",
    "        sigma = 0.5\n",
    "    inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "\n",
    "    inputs[:, :, 1:3] += every_bath_generator(\n",
    "        0, sigma, inputs.shape[0], inputs.shape[1], 2\n",
    "    )\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "    target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "    loss_mask = torch.zeros_like(target_outputs)\n",
    "    mask_indexes_signes = torch.where(target_outputs[:, :, 0] == 1)\n",
    "    mask_indexes_zeros = torch.where(target_outputs[:, :, 0] == 0)\n",
    "    loss_mask[mask_indexes_signes[0], mask_indexes_signes[1], :] = 0.1\n",
    "    loss_mask[mask_indexes_zeros[0], mask_indexes_zeros[1], :] = 1\n",
    "    optimizer.zero_grad()\n",
    "    init_state = LIFAdExState(\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "        torch.rand(batch_size, hidden_size).to(device),\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "    )\n",
    "    # forward + backward + optimize\n",
    "    outputs, _, state = model(\n",
    "        inputs,\n",
    "        init_state,\n",
    "    )\n",
    "\n",
    "    loss = criterion(outputs, target_outputs, loss_mask, state)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss = loss.item()\n",
    "    print(running_loss)\n",
    "    if i % 50 == 49:\n",
    "        with open(\"log_multy.txt\", \"a\") as f:\n",
    "            f.write(\"epoch: {:d} loss: {:0.5f}\\n\".format(i + 1, running_loss / 10))\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                name,\n",
    "            )\n",
    "    if i % 50 == 49:\n",
    "\n",
    "        result = 0\n",
    "        for j in range(10):\n",
    "            try:\n",
    "                del inputs\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                del target_outputs\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                del outputs\n",
    "            except:\n",
    "                pass\n",
    "            torch.cuda.empty_cache()\n",
    "            inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "            inputs[:, :, 1:3] += every_bath_generator(\n",
    "                0, 0.01, inputs.shape[0], inputs.shape[1], 2\n",
    "            )\n",
    "            inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "            target_outputs = (\n",
    "                torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "            )\n",
    "            outputs = model(\n",
    "                inputs,\n",
    "                init_state,\n",
    "            )[0]\n",
    "            type_tasks = list(\n",
    "                np.where(inputs[-1, :, 3:].detach().cpu().numpy() == 1)[1]\n",
    "            )\n",
    "            answers = can.run(\n",
    "                target_outputs[50:, :, 0].cpu(),\n",
    "                outputs[50:, :, 0].cpu(),\n",
    "                target_outputs[50:, :, 1:].cpu(),\n",
    "                outputs[50:, :, 1:].cpu(),\n",
    "                type_tasks,\n",
    "            )\n",
    "            result += answers\n",
    "\n",
    "        accuracy = result / batch_size / 10 * 100\n",
    "        with open(\"accuracy_multy.txt\", \"a\") as f:\n",
    "            f.write(f\"ecpoch = {i}; correct/all = {accuracy}\\n\")\n",
    "    try:\n",
    "        del inputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del target_outputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del outputs\n",
    "        del states\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    init_state = LIFAdExState(\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "        torch.rand(batch_size, hidden_size).to(device),\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "    )\n",
    "    inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "    target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "    result = model(\n",
    "        inputs,\n",
    "        init_state,\n",
    "    )\n",
    "    del inputs, init_state\n",
    "    torch.cuda.empty_cache()\n",
    "    states = result[-1]\n",
    "    s = []\n",
    "    for state in states:\n",
    "        s.append(state.detach().cpu())\n",
    "\n",
    "    s = torch.stack(s)\n",
    "    freq_sequence_new = torch.sort(\n",
    "        torch.mean(torch.mean(s, axis=0), axis=0), dim=0\n",
    "    ).values\n",
    "    for i in range(len(freq_sequence_new)):\n",
    "        plt.plot([i + 1] * 2, [0, freq_sequence_new[i] * 1e3], c=\"b\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.plot(result[0][:, 2, 0].detach().cpu())\n",
    "    plt.plot(result[0][:, 2, 1].detach().cpu())\n",
    "    plt.plot(result[0][:, 2, 2].detach().cpu())\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.plot(target_outputs[:, 2, 0].detach().cpu())\n",
    "    plt.plot(target_outputs[:, 2, 1].detach().cpu())\n",
    "    plt.plot(target_outputs[:, 2, 2].detach().cpu())\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    try:\n",
    "        del inputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del target_outputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del outputs\n",
    "        del states\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save_states = True\n",
    "sorted_tasks = sorted(tasks)\n",
    "re_word = \"Go\"\n",
    "choices_tasks = []\n",
    "values_tasks = []\n",
    "for i in range(len(sorted_tasks)):\n",
    "    if re_word in sorted_tasks[i]:\n",
    "        values_tasks.append(i)\n",
    "    else:\n",
    "        choices_tasks.append(i)\n",
    "can = CorrectAnswerNetwork(choices_tasks, values_tasks, 0.15)\n",
    "inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "inputs[:, :, 1:3] += every_bath_generator(0, 0.01, inputs.shape[0], inputs.shape[1], 2)\n",
    "inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "outputs, states = model(\n",
    "    inputs,\n",
    "    init_state,\n",
    "    additional_current=additional_current_generate(\n",
    "        len(inputs),\n",
    "        batch_size,\n",
    "        hidden_size,\n",
    "    ).to(device),\n",
    ")\n",
    "type_tasks = list(np.where(inputs[-1, :, 3:].detach().cpu().numpy() == 1)[1])\n",
    "answers = can.run(\n",
    "    target_outputs[:, :, 0].cpu(),\n",
    "    outputs[:, :, 0].cpu(),\n",
    "    target_outputs[:, :, 1:].cpu(),\n",
    "    outputs[:, :, 1:].cpu(),\n",
    "    type_tasks,\n",
    ")\n",
    "result += answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "inputs = torch.from_numpy(inputs).type(torch.float).to(device) * 0\n",
    "target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "outputs, states = model(\n",
    "    inputs,\n",
    "    init_state,\n",
    "    additional_current=additional_current_generate(\n",
    "        len(inputs),\n",
    "        batch_size,\n",
    "        hidden_size,\n",
    "    ).to(device),\n",
    ")\n",
    "task_number = 9\n",
    "\n",
    "outputs = outputs.cpu().detach()\n",
    "target_outputs = target_outputs.detach().cpu()\n",
    "s = []\n",
    "for i in range(len(states)):\n",
    "    s.append(states[i].z)\n",
    "s = torch.stack(s).detach().cpu()\n",
    "\n",
    "plt.plot(target_outputs[:, task_number, 0].cpu())\n",
    "plt.plot(outputs[:, task_number, 0].detach().cpu())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(target_outputs[:, task_number, 1].cpu())\n",
    "plt.plot(outputs[:, task_number, 1].detach().cpu())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(target_outputs[:, task_number, 2].cpu())\n",
    "plt.plot(outputs[:, task_number, 2].detach().cpu())\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(s[:, task_number, :].T, aspect=\"auto\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# spike_sequence = torch.stack(spike_sequence)\n",
    "freq_sequence = torch.mean(torch.mean(spike_sequence, axis=0), axis=0)\n",
    "\n",
    "# freq_sequence = sort_elemnts_by_another (freq_sequence, freq_sequence)\n",
    "print(f\"{spike_sequence.shape=}\")\n",
    "print(f\"{freq_sequence.shape=}\")\n",
    "for i in range(len(freq_sequence)):\n",
    "    plt.plot([i + 1] * 2, [0, freq_sequence[i]], c=\"b\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "model.save_states = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cgtasknet.instruments.instrument_subgroups import sort_elemnts_by_another\n",
    "\n",
    "frequency = torch.mean(torch.mean(s, axis=0), axis=0) * 1e3\n",
    "frequency = sort_elemnts_by_another(freq_sequence, frequency)\n",
    "for i in range(len(frequency)):\n",
    "    plt.plot([i + 1] * 2, [0, frequency[i]], c=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(np.where(inputs[-1, :, 3:].detach().cpu().numpy() == 1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестовая функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_network(\n",
    "    test_sigma: float, number_of_trials: int = 100, plot_data: bool = True\n",
    "):\n",
    "    result = 0\n",
    "    for j in tqdm(range(number_of_trials)):\n",
    "        try:\n",
    "            del inputs\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del target_outputs\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del outputs\n",
    "        except:\n",
    "            pass\n",
    "        torch.cuda.empty_cache()\n",
    "        inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "        inputs[:, :, :3] += every_bath_generator(\n",
    "            0, test_sigma, inputs.shape[0], inputs.shape[1], 3\n",
    "        )\n",
    "        inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "        target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "        outputs = model(inputs)[0]\n",
    "        answers = correct_answer(\n",
    "            outputs[:, :, 1:], target_outputs[:, :, 1:], target_outputs[:, :, 0]\n",
    "        )\n",
    "        result += torch.sum(answers).item()\n",
    "\n",
    "    accuracy = result / batch_size / number_of_trials * 100\n",
    "    if plot_data:\n",
    "        plot_results(inputs, target_outputs, outputs)\n",
    "    try:\n",
    "        del inputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del target_outputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del outputs\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование\n",
    "```  np.random.normal(0, 0.01, size=(inputs.shape)) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = test_network(0.01, 1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование\n",
    "```  np.random.normal(0, 0.05, size=(inputs.shape)) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = test_network(0.05, 10)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование\n",
    "```  np.random.normal(0, 0.1, size=(inputs.shape)) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = test_network(0.1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование\n",
    "```  np.random.normal(0, 0.5, size=(inputs.shape)) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = test_network(0.5)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = 0\n",
    "for j in tqdm(range(1)):\n",
    "    try:\n",
    "        del inputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del target_outputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del outputs\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "    inputs[:, :, :3] += np.random.normal(0, 0.5, size=inputs[:, :, :3].shape)\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "    target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "    outputs = model(inputs)[0]\n",
    "    answers = correct_answer(\n",
    "        outputs[:, :, 1:], target_outputs[:, :, 1:], target_outputs[:, :, 0]\n",
    "    )\n",
    "    result += torch.sum(answers).item()\n",
    "\n",
    "accuracy = result / batch_size / 100 * 100\n",
    "print(accuracy)\n",
    "plot_results(inputs, target_outputs, outputs)\n",
    "try:\n",
    "    del inputs\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del target_outputs\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del outputs\n",
    "except:\n",
    "    pass\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = 0\n",
    "for j in tqdm(range(1)):\n",
    "    try:\n",
    "        del inputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del target_outputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del outputs\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "    inputs[:, :, :3] += np.random.normal(0, 0.7, size=inputs[:, :, :3].shape)\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "    target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "    outputs = model(inputs)[0]\n",
    "    answers = correct_answer(\n",
    "        outputs[:, :, 1:], target_outputs[:, :, 1:], target_outputs[:, :, 0]\n",
    "    )\n",
    "    result += torch.sum(answers).item()\n",
    "\n",
    "accuracy = result / batch_size / 100 * 100\n",
    "print(accuracy)\n",
    "plot_results(inputs, target_outputs, outputs)\n",
    "try:\n",
    "    del inputs\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del target_outputs\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del outputs\n",
    "except:\n",
    "    pass\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs = 0\n",
    "outputs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open(\"accuracy_multy.txt\", \"r\") as f:\n",
    "    while line := f.readline():\n",
    "        lines.append(float(line.split(\"=\")[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot([*range(9, 3000, 50)], lines, \".\", linestyle=\"--\", markersize=5)\n",
    "plt.ylabel(r\"Accuracy%\")\n",
    "plt.xlabel(r\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_sigma = 0\n",
    "stop_sigma = 2\n",
    "step_sigma = 0.05\n",
    "sigma_array = np.arange(start_sigma, stop_sigma, step_sigma)\n",
    "for test_sigma in tqdm(sigma_array):\n",
    "    result = 0\n",
    "    for j in range(20):\n",
    "        try:\n",
    "            del inputs\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del target_outputs\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del outputs\n",
    "        except:\n",
    "            pass\n",
    "        torch.cuda.empty_cache()\n",
    "        inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "        inputs[:, :, 1:3] += np.random.normal(\n",
    "            0, test_sigma, size=inputs[:, :, 1:3].shape\n",
    "        )\n",
    "        inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "        target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "        outputs = model(inputs)[0]\n",
    "        type_tasks = list(np.where(inputs[-1, :, 3:].detach().cpu().numpy() == 1)[1])\n",
    "        answers = can.run(\n",
    "            target_outputs[50:, :, 0].cpu(),\n",
    "            outputs[50:, :, 0].cpu(),\n",
    "            target_outputs[50:, :, 1:].cpu(),\n",
    "            outputs[50:, :, 1:].cpu(),\n",
    "            type_tasks,\n",
    "        )\n",
    "        result += answers\n",
    "    accuracy = result / batch_size / 20 * 100\n",
    "    with open(\"accuracy_vs_noise.txt\", \"a\") as f:\n",
    "        f.write(f\"noise={test_sigma}:accuracy={accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "\n",
    "def parser(line_text: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Function parses text in form:\n",
    "    ```v_name_1=v1:v_name_2:v2```\n",
    "    and return (v1, v2)\n",
    "    :param line_text:\n",
    "    :return: (v1, v2)\n",
    "    \"\"\"\n",
    "    line_text = line_text.split(\":\")\n",
    "    print(line_text)\n",
    "    v1 = line_text[0].split(\"=\")[1]\n",
    "    v2 = line_text[1].split(\"=\")[1]\n",
    "    return float(v1), float(v2)\n",
    "\n",
    "\n",
    "x, y = [], []\n",
    "# with open('accuracy_vs_noise.txt', 'r') as f:\n",
    "with open(\n",
    "    r\"accuracy_vs_noise.txt\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    while line := f.readline():\n",
    "        t_x, t_y = parser(line)\n",
    "        x.append(t_x)\n",
    "        y.append(t_y)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, \".\", linestyle=\"--\")\n",
    "# ax.plot([.5]*2, [50, 100])\n",
    "ax.set_ylabel(\"Accuracy,%\")\n",
    "ax.set_xlabel(r\"$\\sigma$\")\n",
    "ax.add_patch(\n",
    "    patches.Rectangle(\n",
    "        (0, 50), 0.5, 50, edgecolor=\"grey\", facecolor=\"grey\", alpha=0.5, fill=True\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "number_of_tasks = 1\n",
    "romo_parameters = RomoTaskRandomModParameters(\n",
    "    romo=RomoTaskParameters(\n",
    "        delay=0.6,\n",
    "        positive_shift_delay_time=0.0,\n",
    "        trial_time=0.1,\n",
    "        positive_shift_trial_time=0.2,\n",
    "    ),\n",
    ")\n",
    "dm_parameters = DMTaskRandomModParameters(\n",
    "    dm=DMTaskParameters(trial_time=0.6, positive_shift_trial_time=0.0)\n",
    ")\n",
    "ctx_parameters = CtxDMTaskParameters(dm=dm_parameters.dm)\n",
    "go_parameters = GoTaskRandomModParameters(\n",
    "    go=GoTaskParameters(\n",
    "        trial_time=0.1,\n",
    "        positive_shift_trial_time=0.8,\n",
    "    )\n",
    ")\n",
    "gort_parameters = GoRtTaskRandomModParameters(\n",
    "    go=GoRtTaskParameters(\n",
    "        trial_time=0.1,\n",
    "        positive_shift_trial_time=0.8,\n",
    "    )\n",
    ")\n",
    "godl_parameters = GoDlTaskRandomModParameters(\n",
    "    go_dl=GoDlTaskParameters(\n",
    "        go=GoTaskParameters(trial_time=0.1, positive_shift_trial_time=0.2),\n",
    "        delay=0.1,\n",
    "        positive_shift_delay_time=1.4,\n",
    "    )\n",
    ")\n",
    "sigma = 0.5\n",
    "tasks = [\n",
    "    \"RomoTask1\",\n",
    "    \"RomoTask2\",\n",
    "    \"DMTask1\",\n",
    "    \"DMTask2\",\n",
    "    \"CtxDMTask1\",\n",
    "    \"CtxDMTask2\",\n",
    "    \"GoTask1\",\n",
    "    \"GoTask2\",\n",
    "    \"GoRtTask1\",\n",
    "    \"GoRtTask2\",\n",
    "    \"GoDlTask1\",\n",
    "    \"GoDlTask2\",\n",
    "]\n",
    "task_dict = {\n",
    "    tasks[0]: romo_parameters,\n",
    "    tasks[1]: romo_parameters,\n",
    "    tasks[2]: dm_parameters,\n",
    "    tasks[3]: dm_parameters,\n",
    "    tasks[4]: ctx_parameters,\n",
    "    tasks[5]: ctx_parameters,\n",
    "    tasks[6]: go_parameters,\n",
    "    tasks[7]: go_parameters,\n",
    "    tasks[8]: gort_parameters,\n",
    "    tasks[9]: gort_parameters,\n",
    "    tasks[10]: godl_parameters,\n",
    "    tasks[11]: godl_parameters,\n",
    "}\n",
    "\n",
    "tasks_sequence = [\n",
    "    MultyReduceTasks(\n",
    "        tasks=task_dict,\n",
    "        batch_size=batch_size,\n",
    "        delay_between=0,\n",
    "        enable_fixation_delay=True,\n",
    "        task_number=i,\n",
    "    )\n",
    "    for i in range(len(tasks))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tasks_and_names = dict([*zip(sorted(tasks), tasks_sequence)])\n",
    "chosed_tasks = [\"CtxDMTask1\", \"GoTask1\", \"GoRtTask1\", \"GoDlTask1\", \"RomoTask1\"]\n",
    "chosed_tasks_dict = {}\n",
    "for key, item in tasks_and_names.items():\n",
    "    if key in chosed_tasks:\n",
    "        chosed_tasks_dict[key] = item\n",
    "print(\"Tasks for PCA\")\n",
    "print(chosed_tasks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from cgtasknet.instruments.instrument_accuracy_network import correct_answer\n",
    "from cgtasknet.net.states import LIFAdExInitState\n",
    "\n",
    "name = f\"Train_dm_and_romo_task_reduce_lif_adex_without_refrac_random_delay_long_a_alpha_{neuron_parameters.alpha}_N_{hidden_size}\"\n",
    "init_state = LIFAdExInitState(batch_size, hidden_size, device=device)\n",
    "data, t_outputs = tasks_and_names[\"DMTask1\"].dataset(2, delay_between=0)\n",
    "data[:, :, 1:3] += every_bath_generator(0, sigma, data.shape[0], data.shape[1], 2)\n",
    "data = torch.from_numpy(data).type(torch.float).to(device)\n",
    "out, states = model(data, init_state.random_state())\n",
    "out = out.detach().cpu().numpy()\n",
    "plt.figure()\n",
    "plt.plot(t_outputs[:, 0, 0])\n",
    "plt.plot(t_outputs[:, 0, 1])\n",
    "plt.plot(t_outputs[:, 0, 2])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(out[:, 0, 0])\n",
    "plt.plot(out[:, 0, 1])\n",
    "plt.plot(out[:, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name == \"alif.recurrent_weights\":\n",
    "        final_parameters = torch.clone(param.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs_final = torch.eig(final_parameters)[0]\n",
    "eigs_initial = torch.eig(initial_parameters)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final = eigs_final[:, 0]\n",
    "y_final = eigs_final[:, 1]\n",
    "\n",
    "x_initial = eigs_initial[:, 0]\n",
    "y_initial = eigs_initial[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_initial, y_initial)\n",
    "plt.scatter(x_final, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_states = True\n",
    "init_state = LIFAdExState(\n",
    "    torch.zeros(batch_size, hidden_size).to(device),\n",
    "    torch.rand(batch_size, hidden_size).to(device),\n",
    "    torch.zeros(batch_size, hidden_size).to(device),\n",
    "    torch.zeros(batch_size, hidden_size).to(device),\n",
    ")\n",
    "inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "\n",
    "inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "result = model(\n",
    "    inputs,\n",
    "    init_state,\n",
    ")\n",
    "del inputs, init_state\n",
    "torch.cuda.empty_cache()\n",
    "states = result[-1]\n",
    "s = []\n",
    "for state in states:\n",
    "    s.append(state.z.detach().cpu())\n",
    "\n",
    "s = torch.stack(s)\n",
    "freq_sequence_new = torch.sort(torch.mean(torch.mean(s, axis=0), axis=0), dim=0).values\n",
    "for i in range(len(freq_sequence_new)):\n",
    "    plt.plot([i + 1] * 2, [0, freq_sequence_new[i] * 1e3], c=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result[0][:, 2, 0].detach().cpu())\n",
    "plt.plot(result[0][:, 2, 1].detach().cpu())\n",
    "plt.plot(result[0][:, 2, 2].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_outputs[:, 2, 0].detach().cpu())\n",
    "plt.plot(target_outputs[:, 2, 1].detach().cpu())\n",
    "plt.plot(target_outputs[:, 2, 2].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(torch.sort(torch.mean(final_parameters, axis=1)).values)\n",
    "plt.plot(torch.sort(torch.mean(initial_parameters, axis=1)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.mean(final_parameters, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.sort(torch.mean(final_parameters, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.zeros((10, 20)), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.sort(torch.mean(initial_parameters, axis=1)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
