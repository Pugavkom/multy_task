{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание\n",
    "\n",
    "## Задачи\n",
    "_Испольуется три задачи:_\n",
    "- DM -- двухальтернативный выбор\n",
    "- Romo -- сравнение двух сигнало через задержку\n",
    "- CtxDM -- DM с контекстом\n",
    "Вход состоит из одного контекстного входа, одного стимула, 6 входов, кодирующих задачи. Выход как и раньше состоит из трех частей: контекстный выход, выходы принятия решения.\n",
    "\n",
    "## Сеть\n",
    " Сеть состоит из lif AdEx нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт всех необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from cgtasknet.instruments.instrument_accuracy_network import CorrectAnswerNetwork\n",
    "from cgtasknet.tasks.reduce import (\n",
    "    CtxDMTaskParameters,\n",
    "    DMTaskParameters,\n",
    "    DMTaskRandomModParameters,\n",
    "    GoDlTaskParameters,\n",
    "    GoDlTaskRandomModParameters,\n",
    "    GoRtTaskParameters,\n",
    "    GoRtTaskRandomModParameters,\n",
    "    GoTaskParameters,\n",
    "    GoTaskRandomModParameters,\n",
    "    MultyReduceTasks,\n",
    "    RomoTaskParameters,\n",
    "    RomoTaskRandomModParameters,\n",
    ")\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "go_task_list_values = np.linspace(0, 1, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определяем устройство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(f\"{device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Определяем датасет\n",
    "Датасет будет состоять из трех типов задач:\n",
    "- DM задача;\n",
    "- Romo задача;\n",
    "- CtxDM задача.\n",
    "_Параметры для последней задачи аналогичны DM задаче_\n",
    "***\n",
    "## Параметры датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "number_of_epochs = 3000\n",
    "number_of_tasks = 1\n",
    "romo_parameters = RomoTaskRandomModParameters(\n",
    "    romo=RomoTaskParameters(\n",
    "        delay=0.2,\n",
    "        positive_shift_delay_time=1.5,\n",
    "        trial_time=0.2,\n",
    "        positive_shift_trial_time=0.4,\n",
    "        answer_time=.25\n",
    "    ),\n",
    ")\n",
    "dm_parameters = DMTaskRandomModParameters(\n",
    "    dm=DMTaskParameters(trial_time=0.3, positive_shift_trial_time=1.5, answer_time=.25)\n",
    ")\n",
    "ctx_parameters = CtxDMTaskParameters(dm=dm_parameters.dm)\n",
    "go_parameters = GoTaskRandomModParameters(\n",
    "    go=GoTaskParameters(\n",
    "        trial_time=0.3,\n",
    "        positive_shift_trial_time=1.5,\n",
    "        value=go_task_list_values,\n",
    "        answer_time=.25\n",
    "    )\n",
    ")\n",
    "gort_parameters = GoRtTaskRandomModParameters(\n",
    "    go_rt=GoRtTaskParameters(\n",
    "        trial_time=0.3,\n",
    "        positive_shift_trial_time=1.5,\n",
    "        answer_time=1,\n",
    "        value=go_task_list_values,\n",
    "    )\n",
    ")\n",
    "godl_parameters = GoDlTaskRandomModParameters(\n",
    "    go_dl=GoDlTaskParameters(\n",
    "        go=GoTaskParameters(trial_time=0.2, positive_shift_trial_time=0.4, answer_time=.25, value=go_task_list_values),\n",
    "        delay=0.2,\n",
    "        positive_shift_delay_time=1.5,\n",
    "\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task parameters:\n",
      "RomoTask1:\n",
      "RomoTaskRandomModParameters(romo=RomoTaskParameters(dt=0.001, trial_time=0.2, answer_time=0.25, value=(None, None), delay=0.2, negative_shift_trial_time=0, positive_shift_trial_time=0.4, negative_shift_delay_time=0, positive_shift_delay_time=1.5), n_mods=2)\n",
      "\n",
      "RomoTask2:\n",
      "RomoTaskRandomModParameters(romo=RomoTaskParameters(dt=0.001, trial_time=0.2, answer_time=0.25, value=(None, None), delay=0.2, negative_shift_trial_time=0, positive_shift_trial_time=0.4, negative_shift_delay_time=0, positive_shift_delay_time=1.5), n_mods=2)\n",
      "\n",
      "DMTask1:\n",
      "DMTaskRandomModParameters(dm=DMTaskParameters(dt=0.001, trial_time=0.3, answer_time=0.25, value=None, negative_shift_trial_time=0, positive_shift_trial_time=1.5), n_mods=2)\n",
      "\n",
      "DMTask2:\n",
      "DMTaskRandomModParameters(dm=DMTaskParameters(dt=0.001, trial_time=0.3, answer_time=0.25, value=None, negative_shift_trial_time=0, positive_shift_trial_time=1.5), n_mods=2)\n",
      "\n",
      "CtxDMTask1:\n",
      "CtxDMTaskParameters(dm=DMTaskParameters(dt=0.001, trial_time=0.3, answer_time=0.25, value=None, negative_shift_trial_time=0, positive_shift_trial_time=1.5), context=None, value=(None, None))\n",
      "\n",
      "CtxDMTask2:\n",
      "CtxDMTaskParameters(dm=DMTaskParameters(dt=0.001, trial_time=0.3, answer_time=0.25, value=None, negative_shift_trial_time=0, positive_shift_trial_time=1.5), context=None, value=(None, None))\n",
      "\n",
      "GoTask1:\n",
      "GoTaskRandomModParameters(go=GoTaskParameters(dt=0.001, trial_time=0.3, answer_time=0.25, value=array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n",
      "       0.71428571, 0.85714286, 1.        ]), negative_shift_trial_time=0, positive_shift_trial_time=1.5), n_mods=2)\n",
      "\n",
      "GoTask2:\n",
      "GoTaskRandomModParameters(go=GoTaskParameters(dt=0.001, trial_time=0.3, answer_time=0.25, value=array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n",
      "       0.71428571, 0.85714286, 1.        ]), negative_shift_trial_time=0, positive_shift_trial_time=1.5), n_mods=2)\n",
      "\n",
      "GoRtTask1:\n",
      "GoRtTaskRandomModParameters(go_rt=GoRtTaskParameters(dt=0.001, trial_time=0.3, answer_time=1, negative_shift_answer_time=0.0, positive_shift_answer_time=0.0, value=array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n",
      "       0.71428571, 0.85714286, 1.        ]), negative_shift_trial_time=0, positive_shift_trial_time=1.5), n_mods=2)\n",
      "\n",
      "GoRtTask2:\n",
      "GoRtTaskRandomModParameters(go_rt=GoRtTaskParameters(dt=0.001, trial_time=0.3, answer_time=1, negative_shift_answer_time=0.0, positive_shift_answer_time=0.0, value=array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n",
      "       0.71428571, 0.85714286, 1.        ]), negative_shift_trial_time=0, positive_shift_trial_time=1.5), n_mods=2)\n",
      "\n",
      "GoDlTask1:\n",
      "GoDlTaskRandomModParameters(go_dl=GoDlTaskParameters(go=GoTaskParameters(dt=0.001, trial_time=0.2, answer_time=0.25, value=array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n",
      "       0.71428571, 0.85714286, 1.        ]), negative_shift_trial_time=0, positive_shift_trial_time=0.4), delay=0.2, negative_shift_delay_time=0.0, positive_shift_delay_time=1.5), n_mods=2)\n",
      "\n",
      "GoDlTask2:\n",
      "GoDlTaskRandomModParameters(go_dl=GoDlTaskParameters(go=GoTaskParameters(dt=0.001, trial_time=0.2, answer_time=0.25, value=array([0.        , 0.14285714, 0.28571429, 0.42857143, 0.57142857,\n",
      "       0.71428571, 0.85714286, 1.        ]), negative_shift_trial_time=0, positive_shift_trial_time=0.4), delay=0.2, negative_shift_delay_time=0.0, positive_shift_delay_time=1.5), n_mods=2)\n",
      "\n",
      "inputs/outputs: 15/3\n"
     ]
    }
   ],
   "source": [
    "sigma = 0.5\n",
    "tasks = [\n",
    "    \"RomoTask1\",\n",
    "    \"RomoTask2\",\n",
    "    \"DMTask1\",\n",
    "    \"DMTask2\",\n",
    "    \"CtxDMTask1\",\n",
    "    \"CtxDMTask2\",\n",
    "    \"GoTask1\",\n",
    "    \"GoTask2\",\n",
    "    \"GoRtTask1\",\n",
    "    \"GoRtTask2\",\n",
    "    \"GoDlTask1\",\n",
    "    \"GoDlTask2\",\n",
    "]\n",
    "task_dict = {\n",
    "    tasks[0]: romo_parameters,\n",
    "    tasks[1]: romo_parameters,\n",
    "    tasks[2]: dm_parameters,\n",
    "    tasks[3]: dm_parameters,\n",
    "    tasks[4]: ctx_parameters,\n",
    "    tasks[5]: ctx_parameters,\n",
    "    tasks[6]: go_parameters,\n",
    "    tasks[7]: go_parameters,\n",
    "    tasks[8]: gort_parameters,\n",
    "    tasks[9]: gort_parameters,\n",
    "    tasks[10]: godl_parameters,\n",
    "    tasks[11]: godl_parameters,\n",
    "}\n",
    "Task = MultyReduceTasks(\n",
    "    tasks=task_dict,\n",
    "    batch_size=batch_size,\n",
    "    delay_between=0,\n",
    "    enable_fixation_delay=True,\n",
    "    mode=\"random\",\n",
    ")\n",
    "\n",
    "print(\"Task parameters:\")\n",
    "for key in task_dict:\n",
    "    print(f\"{key}:\\n{task_dict[key]}\\n\")\n",
    "\n",
    "print(f\"inputs/outputs: {Task.feature_and_act_size[0]}/{Task.feature_and_act_size[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sorted_tasks = sorted(tasks)\n",
    "re_word = 'Go'\n",
    "choices_tasks = []\n",
    "values_tasks = []\n",
    "for i in range(len(sorted_tasks)):\n",
    "    if re_word in sorted_tasks[i]:\n",
    "        values_tasks.append(i)\n",
    "    else:\n",
    "        choices_tasks.append(i)\n",
    "can = CorrectAnswerNetwork(choices_tasks, values_tasks, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инициализация сети и выгрузка на device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from cgtasknet.net import SNNlifadex\n",
    "from norse.torch import LIFAdExParameters\n",
    "\n",
    "feature_size, output_size = Task.feature_and_act_size\n",
    "hidden_size = 600\n",
    "\n",
    "neuron_parameters = LIFAdExParameters(\n",
    "    v_th=torch.as_tensor(0.65),\n",
    "    tau_ada_inv=torch.as_tensor(1 / 2.),\n",
    "    alpha=100,\n",
    "    method=\"super\",\n",
    "    # rho_reset = torch.as_tensor(5)\n",
    ")\n",
    "model = SNNlifadex(\n",
    "    feature_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    neuron_parameters=neuron_parameters,\n",
    "    tau_filter_inv=500,\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Критерий и функция ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-3\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        return torch.sqrt(self.mse(yhat, y))\n",
    "\n",
    "\n",
    "class MaskedMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, mask):\n",
    "        diff2 = (torch.flatten(input) - torch.flatten(target)) ** 2.0 * torch.flatten(mask)\n",
    "        result = torch.sum(diff2) / torch.sum(mask)\n",
    "        return result\n",
    "\n",
    "\n",
    "criterion = MaskedMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация всех эпох\n",
    "> Если память не позволяет, то необходимо генерировать каждую эпоху в основном цикле обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    list_inputs = []\n",
    "    list_t_outputs = []\n",
    "    for i in tqdm(range(number_of_epochs)):\n",
    "        temp_input, temp_t_output = Task.dataset()\n",
    "        temp_input.astype(dtype=np.float16)\n",
    "        temp_t_output.astype(dtype=np.float16)\n",
    "        temp_input[:, :, :] += np.random.normal(0, sigma, size=temp_input.shape)\n",
    "        list_inputs.append(temp_input)\n",
    "        list_t_outputs.append(temp_t_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JIT numba generator (test)\n",
    "TODO: Необходимо добавить в cgtasknet и вызывать оттуда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def every_bath_generator(\n",
    "        start_sigma: float,\n",
    "        stop_sigma: float,\n",
    "        times: int = 1,\n",
    "        batches: int = 1,\n",
    "        actions: int = 1,\n",
    "):\n",
    "    data = np.zeros((times, batches, actions))\n",
    "    for i in range(batches):\n",
    "        data[:, i, :] = np.random.normal(\n",
    "            0, np.random.uniform(start_sigma, stop_sigma), size=(times, actions)\n",
    "        )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from norse.torch import LIF\n",
    "inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "\n",
    "inputs[:, :, 1:3] += every_bath_generator(\n",
    "    0, sigma, inputs.shape[0], inputs.shape[1], 2\n",
    ")\n",
    "inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "l = LIF().to(device)\n",
    "out = l(inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6fc047ac90>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(out.detach().cpu()[:, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alif.input_weights\n",
      "alif.recurrent_weights\n",
      "exp_f.linear.weight\n",
      "exp_f.linear.bias\n"
     ]
    }
   ],
   "source": [
    "for name, _ in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основной цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                         | 2160/3000 [8:45:10<3:24:14, 14.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29623/1146971981.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralnetworks/cgtasknet_train_adex/multy_task/env/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralnetworks/cgtasknet_train_adex/multy_task/env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from cgtasknet.instruments.instrument_accuracy_network import correct_answer\n",
    "from cgtasknet.net.states import LIFAdExInitState\n",
    "from norse.torch import LIFAdExState\n",
    "from norse.torch import LIF\n",
    "name = f\"Train_dm_and_romo_task_reduce_lif_adex_without_refrac_random_delay_long_a_alpha_{neuron_parameters.alpha}_N_{hidden_size}\"\n",
    "init_state = LIFAdExInitState(batch_size, hidden_size, device=device)\n",
    "running_loss = 0\n",
    "sigma = 0\n",
    "l = LIF().to(device)\n",
    "for i in tqdm(range(number_of_epochs)):\n",
    "    if i == 500:\n",
    "        sigma = 0.2\n",
    "    if i == 1000:\n",
    "        sigma = 0.5\n",
    "    inputs, target_outputs = Task.dataset(number_of_tasks)\n",
    "\n",
    "    #inputs[:, :, 1:3] += every_bath_generator(\n",
    "     #   0, sigma, inputs.shape[0], inputs.shape[1], 2\n",
    "    #)\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "    inputs = l(inputs)[0]\n",
    "    target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "    loss_mask = torch.zeros_like(target_outputs)\n",
    "    mask_indexes_signes = torch.where(target_outputs[:, :, 0] == 1)\n",
    "    mask_indexes_zeros = torch.where(target_outputs[:, :, 0] == 0)\n",
    "    loss_mask[mask_indexes_signes[0], mask_indexes_signes[1], :] = 1\n",
    "    loss_mask[mask_indexes_zeros[0], mask_indexes_zeros[1], :] = 5\n",
    "    optimizer.zero_grad()\n",
    "    init_state = LIFAdExState(\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "        torch.rand(batch_size, hidden_size).to(device),\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "    )\n",
    "    # forward + backward + optimize\n",
    "    outputs, _ = model(inputs, init_state)\n",
    "\n",
    "    loss = criterion(outputs, target_outputs, loss_mask)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 50 == 49:\n",
    "        with open(\"log_multy.txt\", \"a\") as f:\n",
    "            f.write(\"epoch: {:d} loss: {:0.5f}\\n\".format(i + 1, running_loss / 10))\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                name,\n",
    "            )\n",
    "    if i % 50 == 49:\n",
    "\n",
    "        result = 0\n",
    "        for j in range(10):\n",
    "            try:\n",
    "                del inputs\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                del target_outputs\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                del outputs\n",
    "            except:\n",
    "                pass\n",
    "            torch.cuda.empty_cache()\n",
    "            inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "            inputs[:, :, 1:3] += every_bath_generator(\n",
    "                0, 0.01, inputs.shape[0], inputs.shape[1], 2\n",
    "            )\n",
    "            inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "            target_outputs = (\n",
    "                torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "            )\n",
    "            outputs = model(inputs)[0]\n",
    "            type_tasks = list(np.where(inputs[-1, :, 3:].detach().cpu().numpy() == 1)[1])\n",
    "            answers = can.run(target_outputs[50:, :, 0].cpu(), outputs[50:, :, 0].cpu(),\n",
    "                              target_outputs[50:, :, 1:].cpu(), outputs[50:, :, 1:].cpu(), type_tasks)\n",
    "            result += answers\n",
    "\n",
    "        accuracy = result / batch_size / 10 * 100\n",
    "        with open(\"accuracy_multy.txt\", \"a\") as f:\n",
    "            f.write(f\"ecpoch = {i}; correct/all = {accuracy}\\n\")\n",
    "    try:\n",
    "        del inputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del target_outputs\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        del outputs\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████████▌                                                                                                                                                                                                                                                                                                                                                                                   | 1/40 [02:23<1:33:12, 143.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.69999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███████████████████                                                                                                                                                                                                                                                                                                                                                                          | 2/40 [04:46<1:30:39, 143.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████████████████                                                                                                                                                                                                                                                                                                                                                                          | 2/40 [05:27<1:43:45, 163.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29623/3312600278.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtype_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_for_check\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         answers = can.run(target_outputs[50:, :, 0].cpu(), outputs[50:, :, 0].cpu(), target_outputs[50:, :, 1:].cpu(),\n",
      "\u001b[0;32m~/neuralnetworks/cgtasknet_train_adex/multy_task/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralnetworks/cgtasknet_train_adex/multy_task/env/lib/python3.7/site-packages/cgtasknet-0.0.1-py3.7.egg/cgtasknet/net/lifadex.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     ]:\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malif\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralnetworks/cgtasknet_train_adex/multy_task/env/lib/python3.7/site-packages/cgtasknet-0.0.1-py3.7.egg/cgtasknet/net/save_states.py\u001b[0m in \u001b[0;36msave_states\u001b[0;34m(x, save_states, layer, state)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralnetworks/cgtasknet_train_adex/multy_task/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralnetworks/cgtasknet_train_adex/multy_task/env/lib/python3.7/site-packages/norse-0.0.7.post1-py3.7-linux-x86_64.egg/norse/torch/module/snn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, state)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             )\n\u001b[1;32m    325\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuralnetworks/cgtasknet_train_adex/multy_task/env/lib/python3.7/site-packages/norse-0.0.7.post1-py3.7-linux-x86_64.egg/norse/torch/functional/lif_adex.py\u001b[0m in \u001b[0;36mlif_adex_step\u001b[0;34m(input_tensor, state, input_weights, recurrent_weights, p, dt)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# compute voltage updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mdv_leak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_leak\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mdv_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta_T\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_th\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0mdv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau_mem_inv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdv_leak\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdv_exp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mv_decayed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from norse.torch import LIFAdExState\n",
    "go_accuracy = 0.15\n",
    "can = CorrectAnswerNetwork(choices_tasks, values_tasks, go_accuracy)\n",
    "start_sigma = 0\n",
    "stop_sigma = 2\n",
    "step_sigma = 0.05\n",
    "sigma_array = np.arange(start_sigma, stop_sigma, step_sigma)\n",
    "for test_sigma in tqdm(sigma_array):\n",
    "    result = 0\n",
    "    for j in range(20):\n",
    "        try:\n",
    "            del inputs\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del target_outputs\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del outputs\n",
    "        except:\n",
    "            pass\n",
    "        torch.cuda.empty_cache()\n",
    "        inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "        #inputs[:, :, 1:3] += np.random.normal(0, test_sigma, size=inputs[:, :, 1:3].shape)\n",
    "        inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "        inputs_for_check = torch.clone(inputs)\n",
    "        inputs = l(inputs)[0]\n",
    "        target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "        init_state = LIFAdExState(\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "        torch.rand(batch_size, hidden_size).to(device),\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "        torch.zeros(batch_size, hidden_size).to(device),\n",
    "    )\n",
    "        outputs = model(inputs, init_state)[0]\n",
    "        type_tasks = list(np.where(inputs_for_check[-1, :, 3:].detach().cpu().numpy() == 1)[1])\n",
    "        answers = can.run(target_outputs[50:, :, 0].cpu(), outputs[50:, :, 0].cpu(), target_outputs[50:, :, 1:].cpu(),\n",
    "                          outputs[50:, :, 1:].cpu(), type_tasks)\n",
    "        result += answers\n",
    "    accuracy = result / batch_size / 20 * 100\n",
    "    print(accuracy)\n",
    "    #with open(f\"accuracy_vs_noise_{go_accuracy}_init_state.txt\", \"a\") as f:\n",
    "        #f.write(f\"noise={test_sigma}:accuracy={accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_states = True\n",
    "out_and_save_states = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "states = out_and_save_states[1]\n",
    "for state in states:\n",
    "    s.append(state.z.detach().cpu())\n",
    "s = torch.stack(s).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6f7cccad90>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( sorted(1e3 *np.mean(np.mean(s, axis=1), axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "go_accuracy = 0.07\n",
    "can = CorrectAnswerNetwork(choices_tasks, values_tasks, go_accuracy)\n",
    "start_sigma = 0\n",
    "stop_sigma = 2\n",
    "step_sigma = 0.05\n",
    "sigma_array = np.arange(start_sigma, stop_sigma, step_sigma)\n",
    "for test_sigma in tqdm(sigma_array):\n",
    "    result = 0\n",
    "    for j in range(20):\n",
    "        try:\n",
    "            del inputs\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del target_outputs\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            del outputs\n",
    "        except:\n",
    "            pass\n",
    "        torch.cuda.empty_cache()\n",
    "        inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "        inputs[:, :, 1:3] += np.random.normal(0, test_sigma, size=inputs[:, :, 1:3].shape)\n",
    "        inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "        target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "        outputs = model(inputs)[0]\n",
    "        type_tasks = list(np.where(inputs[-1, :, 3:].detach().cpu().numpy() == 1)[1])\n",
    "        answers = can.run(target_outputs[50:, :, 0].cpu(), outputs[50:, :, 0].cpu(), target_outputs[50:, :, 1:].cpu(),\n",
    "                          outputs[50:, :, 1:].cpu(), type_tasks)\n",
    "        result += answers\n",
    "    accuracy = result / batch_size / 20 * 100\n",
    "    with open(f\"accuracy_vs_noise_{go_accuracy}.txt\", \"a\") as f:\n",
    "        f.write(f\"noise={test_sigma}:accuracy={accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
