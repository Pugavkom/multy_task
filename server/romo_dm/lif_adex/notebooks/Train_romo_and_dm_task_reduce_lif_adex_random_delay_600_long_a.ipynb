{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Two task network \n",
    "\n",
    "## Network has some inputs\n",
    "\n",
    "1. The fixation. \n",
    "1. The first context mod. \n",
    "1. The second ontext mod. \n",
    "\n",
    "## Network has five outputs\n",
    "1. The fixation. \n",
    "1. The first output.\n",
    "1. The second output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"./images/Sheme.png\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "> Learning rule: superspike\n",
    "\n",
    "> Neuron type: LifAdex + refrac\n",
    "\n",
    "> Task: romo\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt  # for analys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from cgtasknet.net.lifadex import SNNlifadex\n",
    "from cgtasknet.tasks.reduce import DMTaskParameters\n",
    "from cgtasknet.tasks.reduce import DMTaskRandomModParameters\n",
    "from cgtasknet.tasks.reduce import MultyReduceTasks\n",
    "from cgtasknet.tasks.reduce import RomoTaskParameters\n",
    "from cgtasknet.tasks.reduce import RomoTaskRandomModParameters\n",
    "from norse.torch.functional.lif_adex import LIFAdExParameters\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step -1: Create dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "print(f'Device: {(\"gpu (cuda)\" if device.type==\"cuda\" else \"cpu\")}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: gpu (cuda)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "%matplotlib widget\n",
    "batch_size = 50\n",
    "number_of_tasks = 1\n",
    "romo_parameters = RomoTaskRandomModParameters(\n",
    "    romo=RomoTaskParameters(\n",
    "        delay=0.1,\n",
    "        positive_shift_delay_time=0.5,\n",
    "        trial_time=0.1,\n",
    "        positive_shift_trial_time=0.2,\n",
    "    ),\n",
    "    n_mods=1\n",
    ")\n",
    "dm_parameters = DMTaskRandomModParameters(\n",
    "    dm=DMTaskParameters(trial_time=0.1, positive_shift_trial_time=0.8),\n",
    "    n_mods=1\n",
    ")\n",
    "\n",
    "task_names = [\"RomoTask1\", \"DMTask1\"]\n",
    "tasks = dict()\n",
    "tasks[task_names[0]] = romo_parameters\n",
    "tasks[task_names[1]] = dm_parameters\n",
    "# task_parameters = RomoTaskParameters(delay=0.1, positive_shift_delay_time=.0, trial_time = 0.2, positive_shift_trial_time=.0)\n",
    "Task = MultyReduceTasks(\n",
    "    tasks=tasks,\n",
    "    batch_size=batch_size,\n",
    "    enable_fixation_delay=True,\n",
    "    sequence_bathces=True,\n",
    "    number_of_inputs=1\n",
    ")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "n_mods = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1.1: Create model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "feature_size, output_size = Task.feature_and_act_size\n",
    "hidden_size = 450\n",
    "\n",
    "neuron_parameters = LIFAdExParameters(\n",
    "\n",
    "        v_th=torch.as_tensor(0.65),\n",
    "        tau_ada_inv=0.5 + (6 - 0.5) * torch.rand(hidden_size).to(device),\n",
    "        alpha=100,\n",
    "        # method='heavi_erfc',\n",
    "        method=\"super\",\n",
    "\n",
    "    # rho_reset = torch.as_tensor(5)\n",
    ")\n",
    "model = SNNlifadex(\n",
    "    feature_size,\n",
    "    hidden_size,\n",
    "    output_size,\n",
    "    neuron_parameters=neuron_parameters,\n",
    "    tau_filter_inv=500,\n",
    ").to(device)\n",
    "# model = torch.nn.DataParallel(model, device_ids=[0]).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tau_ada_inv_distrib = neuron_parameters.tau_ada_inv.cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "np.save(f\"tau_ada_inv_alpha={neuron_parameters.alpha}\", tau_ada_inv_distrib)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1.2: Save pre-learning weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "weights_pre_l = []\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"name = {name}\")\n",
    "        if param.requires_grad:\n",
    "            weights_pre_l.append((param).cpu().numpy())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = alif.input_weights\n",
      "name = alif.recurrent_weights\n",
      "name = exp_f.linear.weight\n",
      "name = exp_f.linear.bias\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: loss and creterion "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        return torch.sqrt(self.mse(yhat, y))\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "name = f\"Train_dm_and_romo_task_reduce_lif_adex_without_refrac_random_delay_long_a_alpha_{neuron_parameters.alpha}_N_{hidden_size}\"\n",
    "name"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "'Train_dm_and_romo_task_reduce_lif_adex_without_refrac_random_delay_long_a_alpha_100_N_450'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Precreate data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "l_inputs = []\n",
    "l_outputs = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(2000)):\n",
    "    tmp_inputs, tmp_target_outputs = Task.dataset(number_of_tasks, delay_between=0)\n",
    "    tmp_inputs += np.random.normal(0, 0.01, size=tmp_inputs.shape)\n",
    "    l_inputs.append(tmp_inputs)\n",
    "    l_outputs.append(tmp_target_outputs)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:20<00:00, 98.58it/s] \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Train loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from cgtasknet.net.states import LIFAdExRefracInitState\n",
    "from cgtasknet.instruments.instrument_accuracy_network import correct_answer\n",
    "\n",
    "init_state = LIFAdExRefracInitState(batch_size, hidden_size, device=device)\n",
    "\n",
    "#\n",
    "\n",
    "running_loss = 0\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(2000)):\n",
    "    inputs = torch.from_numpy(l_inputs[i]).type(torch.float).to(device)\n",
    "    target_outputs = torch.from_numpy(l_outputs[i]).type(torch.float).to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs, _ = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, target_outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 10 == 9:\n",
    "        with open(\"log_multy.txt\", \"a\") as f:\n",
    "            f.write(\"epoch: {:d} loss: {:0.5f}\\n\".format(i + 1, running_loss / 10))\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                name,\n",
    "            )\n",
    "    if i % 10 == 9:\n",
    "\n",
    "        result = 0\n",
    "        for j in range(10):\n",
    "            inputs, target_outputs = Task.dataset(1, delay_between=0)\n",
    "            inputs += np.random.normal(0, 0.01, size=(inputs.shape))\n",
    "            inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "            target_outputs = (\n",
    "                torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "            )\n",
    "            outputs = model(inputs)[0]\n",
    "            answers = correct_answer(\n",
    "                outputs[:, :, 1:], target_outputs[:, :, 1:], target_outputs[:, :, 0]\n",
    "            )\n",
    "            result += torch.sum(answers).item()\n",
    "        accuracy = result / batch_size / 10 * 100\n",
    "        with open(\"accuracy_multy.txt\", \"a\") as f:\n",
    "            f.write(f\"ecpoch = {i}; correct/all = {accuracy}\\n\")\n",
    "print(\"Finished Training\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1289/2000 [6:22:23<91:01:08, 460.86s/it]   "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mfrom_numpy(l_inputs[i])\u001B[38;5;241m.\u001B[39mtype(torch\u001B[38;5;241m.\u001B[39mfloat)\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(l_inputs[i]).type(torch.float).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cgtasknet.instruments.instrument_accuracy_network import correct_answer\n",
    "from tqdm import tqdm\n",
    "\n",
    "task_parameters_test = RomoTaskParameters(\n",
    "    delay=0.5,\n",
    "    positive_shift_delay_time=0,\n",
    "    trial_time=0.1,\n",
    "    positive_shift_trial_time=0.2,\n",
    ")\n",
    "result = 0\n",
    "model = model.to(device)\n",
    "for i in tqdm(range(100)):\n",
    "    inputs, target_outputs = Task.dataset(3, delay_between=0)\n",
    "    inputs += np.random.normal(0, 0.01, size=inputs.shape)\n",
    "    inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "    target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "    outputs = model(inputs)[0]\n",
    "    answers = correct_answer(\n",
    "        outputs[:, :, 1:], target_outputs[:, :, 1:], target_outputs[:, :, 0]\n",
    "    )\n",
    "    result += torch.sum(answers).item()\n",
    "round(result / batch_size / 100 * 100, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "start = 30\n",
    "for batch in range(start, 9 + start, 1):\n",
    "    fig.add_subplot(520 + batch + 1 - start)\n",
    "    plt.plot(outputs[:, batch, 1].detach().cpu())\n",
    "    plt.plot(outputs[:, batch, 2].detach().cpu())\n",
    "    plt.plot(target_outputs.detach().cpu()[:, batch, 1], label=f\"t_out{2}\")\n",
    "    plt.plot(target_outputs.detach().cpu()[:, batch, 2], label=f\"t_out{3}\")\n",
    "    plt.plot(inputs[:, batch, 1].detach().cpu())\n",
    "    plt.legend()\n",
    "    # plt.plot(inputs[:, 0, 0].detach().cpu())\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "start = 30\n",
    "for batch in range(start, 9 + start, 1):\n",
    "    fig.add_subplot(520 + batch + 1 - start)\n",
    "    plt.plot(inputs[:, batch, 0].detach().cpu())\n",
    "    plt.plot(inputs[:, batch, 1].detach().cpu())\n",
    "\n",
    "    # plt.legend()\n",
    "    # plt.plot(inputs[:, 0, 0].detach().cpu())\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(inputs[:, batch, 1].detach().cpu())\n",
    "\n",
    "plt.plot(target_outputs.detach().cpu()[:, batch, 1])\n",
    "plt.plot(target_outputs.detach().cpu()[:, batch, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.save(model.state_dict(), name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if True:\n",
    "    model.load_state_dict(torch.load(name))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dmparamsv = dmparams1\n",
    "Taskplot = RomoTask(params=dmparamsv, batch_size=1, delay_beetween=100)\n",
    "inputs, target_outputs = Taskplot.dataset(10)\n",
    "inputs += np.random.normal(0, 0.01, size=(inputs.shape))\n",
    "inputs = torch.from_numpy(inputs).type(torch.float).to(device)\n",
    "target_outputs = torch.from_numpy(target_outputs).type(torch.float).to(device)\n",
    "outputs, states = model(inputs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "for i in range(inputs.shape[2]):\n",
    "    plt.plot(inputs[:, 0, i].detach().cpu().numpy(), label=fr\"$u_{i + 1}$\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "for i in range(outputs.shape[2]):\n",
    "    plt.plot(outputs[:, 0, i].detach().cpu().numpy(), label=fr\"$u_{i + 1}$\")\n",
    "    plt.plot(\n",
    "        target_outputs[:, 0, i].detach().cpu().numpy(), label=fr\"$u^{{target}}_{i + 1}$\"\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plt.plot(\n",
    "    outputs[:, 0, -2].detach().cpu().numpy() - outputs[:, 0, -1].detach().cpu().numpy(),\n",
    "    label=fr\"$u_2 - u_3$\",\n",
    ")\n",
    "plt.plot(target_outputs[:, 0, -2].detach().cpu().numpy(), label=fr\"$u^{{target}}_{2}$\")\n",
    "plt.plot(target_outputs[:, 0, -1].detach().cpu().numpy(), label=fr\"$u^{{target}}_{3}$\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "for i in range(inputs.shape[2]):\n",
    "    plt.plot(inputs[:, 0, i].detach().cpu().numpy(), label=fr\"$u_{i + 1}$\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(target_outputs[:, 0, 1].detach().cpu().numpy(), label=fr\"$y_{2}$\")\n",
    "plt.plot(target_outputs[:, 0, 2].detach().cpu().numpy(), label=fr\"$y_{3}$\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "weights_post_l = []\n",
    "with torch.no_grad():\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            weights_post_l.append((param).cpu().numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "for i in range(len(weights_pre_l) - 1):\n",
    "    plt.imshow((weights_pre_l[i]), aspect=\"auto\", cmap=\"jet\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "for i in range(len(weights_pre_l) - 1):\n",
    "    plt.imshow(\n",
    "        (weights_post_l[i]),\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"jet\",\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "for i in range(len(weights_pre_l) - 1):\n",
    "    plt.imshow(\n",
    "        (weights_post_l[i] - weights_pre_l[i]),\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"jet\",\n",
    "        vmin=-0.2,\n",
    "        vmax=0.4,\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "305609147ade9861f62c37f84739a2a79a1a74536f27d129a7c8364bcef8fb28"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('env': venv)"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}